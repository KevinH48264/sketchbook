{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d769a465",
   "metadata": {},
   "source": [
    "# The First Law of Complexodynamics\n",
    "\n",
    "**Focus**: \n",
    "\n",
    "**References**: \n",
    "- The First Law of Complexodynamics (https://scottaaronson.blog/?p=762)\n",
    "\n",
    "**Purpose**: \n",
    "\n",
    "**Approach**: \n",
    "\n",
    "**Result**: \n",
    "\n",
    "\n",
    "**Definitions**: \n",
    "- Soph(x) = length of the shortest program that describes a set S of which x is a \"random\" or \"generic\" member.\n",
    "\n",
    "**Notes**:\n",
    "\n",
    "One goal is to understand what a high sophistication example is (low Soph(x))\n",
    "\n",
    "Examples of Sophistication\n",
    "1. High entropy/randomness, low sophistication/non-randomness example = Assume $x$ is a perfectly random $n$-bit string. The only set $S$ that works is $S = \\{x\\}$, ie |S| = 1 and the set is x itself because anything larger (with more strings) would be a larger program. \n",
    "    - Soph(x) = $K(S) \\approx n$ which is just as long as describing x itself. So random strings have high Kolmogorov complexity because $K(x) = n$ but low sophistication because $K(S) = n$ (high Soph(x) = low sophistication surprisingly?).\n",
    "\n",
    "2. Low entropy/randomness, high sophistication/non-randomness example = Assume $x$ is the first $n$ digits of $\\pi$. The shortest set $S$ that works is $S = \\text{ digits of } \\pi$, so $K(S) \\approx O(1) \\text{ or } O(log(n))$ to encode \"$\\pi$\". \n",
    "    - $O(log(n))$ is to encode how many digits to output\n",
    "    - Soph(x) = $K(S) \\approx log(n)$ which is shorter than describing $x$ itself (n). So this patterned string has high Kolmogorov complexity because $K(x) = n$ and high sophistication because $K(S) = log(n)$ (low Soph(x) = high sophistication.)\n",
    "\n",
    "\n",
    "Q: What does this second condition mean: \"K(x|S) ≥ log2(|S|) – c, for some constant c.  (In other words, one can distill all the “nonrandom” information in x just by saying that x belongs that S.)\"?\n",
    " - log2(|S|) = # of bits needed to identify a particular element of $S$ if you just indexed it.\n",
    " - K(x | S) = how many bits needed to specify $x$, given you already know the set S and have membership access\n",
    " - Knowing S doesn't make x cheaper to describe than just picking an element out of S at random (that's the best that you can do).\n",
    "- I'm pretty sure the second bullet is that log(|S|) is the best you can do to capture all the nonrandom information in x\n",
    "\n",
    "Alright my sense was that the math didn't really check out here, but intuitively if Soph(x) is the lenght of the shortest computer program, it does make sense that any string x with small Kolmogorov complexity has small sophistication because Soph(x) = K(S) = K(x) which is already low AND any string x with high Kolmogorov complexity like a uniformly-random string also has small sophistication if S = set of all n-bit strings.\n",
    "    - So effectively you're always trying to find a shorter program S than K(x) s.t. if you do, there will be small sophistication. For random x, Soph(x) = n.\n",
    "\n",
    "\n",
    "\n",
    "**FAQs**:\n",
    "\n",
    "**Action items**:\n",
    "- Note: ideas build on one another, so it might make more sense to build upon the previous set of notes instead of re-creating from scratch. Otherwise, you lose definitions.\n",
    "- Continue from \"what does any of this have to do with coffee cups?\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
